# ğŸ“¡ End-to-End Path Loss Prediction Using Machine Learning (RF / 5G)

This project implements a **complete machine learning pipeline** to predict **path loss in RF / cellular communication environments** using real-world network measurement data.  
The system models how signal strength degrades due to distance, environment, and network conditions, and compares multiple ML algorithms to identify the best-performing model.

---

## ğŸ¯ Project Objectives

- Generate a realistic **path loss target variable** from received signal strength  
- Perform **exploratory data analysis (EDA)** and **time-series analysis**
- Apply **feature engineering & preprocessing**
- Train and compare **multiple regression models**
- Evaluate performance using **RMSE, MAE, and RÂ²**
- Visualize results using **professional plots**
- Save models and preprocessing artifacts for reuse
- Provide an optional **Streamlit interface** for inference

---

## ğŸ“‚ Dataset Overview

The dataset represents **cellular / RF communication measurements** collected over time.

### Key Features Used

| Feature | Description |
|------|------------|
| Timestamp | Time of measurement |
| Signal Strength (dBm) | Received signal power |
| SNR | Signal-to-Noise Ratio |
| Call Duration (s) | Duration of call |
| Environment | Urban / Suburban / Home / Open |
| Attenuation | Estimated environmental loss |
| Distance to Tower (km) | Distance from base station |
| Tower ID | Cellular tower identifier |
| User ID | User identifier |
| Call Type | Voice / Data |

### ğŸ¯ Target Variable

**Path Loss (dB)** is generated using RF principles:
Path Loss (dB) = Transmitted Power (assumed constant) âˆ’ Received Signal Strength (dBm)

This allows the ML models to learn **signal degradation behavior** under varying conditions.

---

## ğŸ“„ Sample Training Data

| Timestamp | Signal Strength (dBm) | SNR | Call Duration | Environment | Attenuation | Distance (km) | Call Type |
|---------|----------------------|-----|---------------|-------------|-------------|---------------|-----------|
| 01-03-2024 17:46 | -84.11 | 25.94 | 1713.8 | Urban | 14.69 | 2.24 | Data |
| 01-04-2024 17:29 | -87.80 | 15.93 | 345.37 | Home | 6.21 | 5.00 | Voice |
| 01-05-2024 17:14 | -116.57 | 14.70 | 259.28 | Open | 4.49 | 8.70 | Voice |

Full dataset: **Train Data.csv**

---

## ğŸ§  Machine Learning Models Implemented

The following regression models were trained and compared:

- Linear Regression  
- Ridge Regression  
- LASSO Regression  
- Elastic Net  
- Random Forest Regressor  
- Gradient Boosting Regressor  
- XGBoost Regressor  
- LightGBM Regressor  
- Support Vector Regressor (SVR)

**Hyperparameter tuning** was performed using **RandomizedSearchCV** with cross-validation.

---

## âš™ï¸ ML Pipeline

1. Data Loading  
2. Data Cleaning & Imputation  
3. Target (Path Loss) Generation  
4. Exploratory Data Analysis  
5. Feature Engineering  
6. Train / Validation / Test Split  
7. Model Training & Hyperparameter Tuning  
8. Model Evaluation & Comparison  
9. Visualization & Interpretation  
10. Model & Preprocessor Serialization  

---

## ğŸ“Š Visual Results

### ğŸ”¹ Dataset Analysis
![Dataset Analysis](Dataset%20Analysis.png)

### ğŸ”¹ Feature Correlation Matrix
![Feature Correlation](Feature%20Correlation%20Matrix.png)

### ğŸ”¹ Model Performance Comparison
![Model Comparison](Model%20Performance%20Comparison.png)

### ğŸ”¹ Prediction Error Analysis
![Error Analysis](Predictions%20Error%20Analysis.png)

### ğŸ”¹ Time Series Analysis
![Time Series](Time%20Series%20Analysis.png)

### ğŸ”¹ Process Flow Diagram
![Process Flow](process_flow_diagram.svg)

---

## ğŸ“ˆ Evaluation Metrics

Each model was evaluated using:

- **RMSE** â€“ Penalizes large prediction errors  
- **MAE** â€“ Average absolute error  
- **RÂ² Score** â€“ Variance explained by the model  

These metrics help identify **accuracy, robustness, and generalization ability**.

---

## ğŸ—‚ï¸ Project Structure

PATH_LOSS_PREDICTION/ â”‚ â”œâ”€â”€ artifacts/ â”‚ â”œâ”€â”€ all_best_models/ â”‚ â”œâ”€â”€ best_model.joblib â”‚ â”œâ”€â”€ feature_info.joblib â”‚ â”œâ”€â”€ model_performance_results.xlsx â”‚ â””â”€â”€ preprocessor.joblib â”‚ â”œâ”€â”€ rf_env/ # Virtual environment â”œâ”€â”€ path_loss_prediction.ipynb # Main experiment notebook â”œâ”€â”€ streamlit_app.py # Optional UI â”œâ”€â”€ Train Data.csv â”œâ”€â”€ Dataset Analysis.png â”œâ”€â”€ Feature Correlation Matrix.png â”œâ”€â”€ Model Performance Comparison.png â”œâ”€â”€ Predictions Error Analysis.png â”œâ”€â”€ Time Series Analysis.png â”œâ”€â”€ Process Flow diagram.png â”œâ”€â”€ process_flow_diagram.svg â”œâ”€â”€ requirements.txt â””â”€â”€ readme.md

---

## ğŸ–¥ï¸ Streamlit Application Features

The Streamlit application supports two prediction modes:

### ğŸ”¹ Single Prediction
Users can manually enter RF and environmental parameters such as:
- Signal strength
- Distance to tower
- Environment type
- Attenuation and SNR

The system predicts the corresponding **path loss value in real time**.

### ğŸ”¹ Batch Prediction
Users can upload a CSV file containing multiple samples.
- The model performs predictions for all rows
- Output is displayed as a table
- Predicted results can be downloaded as a CSV file

This enables efficient evaluation of large datasets.

Run locally: streamlit run streamlit_app.py

---

## ğŸ§ª Key Observations

- Tree-based models (Random Forest, XGBoost, LightGBM) outperform linear models
- Distance and signal strength dominate path loss prediction
- Environmental factors introduce non-linear effects
- Feature engineering significantly improves performance

---

## ğŸ”® Future Scope

- Deep learning models (ANN, LSTM)
- Comparison with **3GPP theoretical path loss models**
- Real-time streaming inference
- REST API deployment
- Geospatial modeling using coordinates

---

## ğŸ“Œ Usage & Applicability

This project demonstrates practical machine learning skills applied to real-world RF and telecom data.  
It is suitable for:
- Academic research and learning
- AI/ML portfolio and resume projects
- Applied data science and regression modeling use cases